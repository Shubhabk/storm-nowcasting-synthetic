{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07c0453-eb8a-447b-97ab-b0477e4d692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating storms with all specified changes ---\n",
      "Generated 435202 rows for 50000 storms → saved to scenario6_fixed_peak_50000.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# ------------------ MASTER INTENSITY PROFILE (Simplified) ------------------\n",
    "def generate_master_intensity_profile():\n",
    "    \"\"\"Returns an empty list as the master profile is no longer used.\"\"\"\n",
    "    return []\n",
    "\n",
    "# ------------------ STORM CELL GENERATION (Modified) ------------------\n",
    "def generate_storm_cell_lifecycle(\n",
    "    cell_id,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    target_peak_intensity_dbz=75,\n",
    "    time_step_minutes=5,\n",
    "    base_size_pixels=120,\n",
    "    base_vx=0.0,\n",
    "    base_vy=2.0,\n",
    "    movement_randomness_scale=0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a single storm cell's lifecycle with all requested properties.\n",
    "    The intensity calculation is fixed to ensure a consistent peak intensity.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "    # Random formation time\n",
    "    time_range_seconds = (end_date - start_date).total_seconds()\n",
    "    formation_time = start_date + datetime.timedelta(seconds=random.uniform(0, time_range_seconds))\n",
    "\n",
    "    # Lifetime from Normal Distribution with min/max bounds\n",
    "    mean_lifetime_hours = 40 / 60  # ~40 minutes\n",
    "    std_dev_lifetime_hours = 0.3\n",
    "    min_lifetime_hours = 15 / 60   # 15 minutes\n",
    "    max_lifetime_hours = 1.5       # 1.5 hours\n",
    "    \n",
    "    lifetime_hours = np.random.normal(mean_lifetime_hours, std_dev_lifetime_hours)\n",
    "    lifetime_hours = max(min_lifetime_hours, min(max_lifetime_hours, lifetime_hours))\n",
    "\n",
    "    lifetime_delta = datetime.timedelta(hours=lifetime_hours)\n",
    "    dissipation_time = formation_time + lifetime_delta\n",
    "\n",
    "    # Starting position\n",
    "    x_position, y_position = 0, 0\n",
    "\n",
    "    previous_intensity = 0\n",
    "    peak_relative_time = 0.5 \n",
    "\n",
    "    current_time = formation_time\n",
    "    while current_time <= dissipation_time:\n",
    "        time_elapsed_seconds = (current_time - formation_time).total_seconds()\n",
    "        \n",
    "        # Normalize time elapsed to a 0-1 range\n",
    "        progress = time_elapsed_seconds / lifetime_delta.total_seconds()\n",
    "        \n",
    "        # --- FIX: Ensure peak intensity is hit exactly at the midpoint ---\n",
    "        if abs(progress - peak_relative_time) < (time_step_minutes / 60) / (lifetime_hours * 2):\n",
    "            intensity_dbz = target_peak_intensity_dbz\n",
    "        elif progress < peak_relative_time:\n",
    "            # Growth phase: Logistic curve from 0 to target_peak_intensity_dbz\n",
    "            intensity_dbz = target_peak_intensity_dbz / (1 + np.exp(-10 * (progress - peak_relative_time)))\n",
    "        else:\n",
    "            # Decay phase: Exponential decay from target_peak_intensity_dbz to 0\n",
    "            decay_progress = (progress - peak_relative_time) / (1 - peak_relative_time)\n",
    "            intensity_dbz = target_peak_intensity_dbz * np.exp(-10 * decay_progress)\n",
    "\n",
    "        # Ensure intensity does not go below zero\n",
    "        intensity_dbz = max(0.0, intensity_dbz)\n",
    "        \n",
    "        # Intensity change rate\n",
    "        intensity_change_rate = (intensity_dbz - previous_intensity) / (time_step_minutes / 60)\n",
    "\n",
    "        # Size scaling\n",
    "        size_pixels = 20 + (intensity_dbz / target_peak_intensity_dbz) * base_size_pixels if target_peak_intensity_dbz > 0 else 20\n",
    "        size_pixels = size_pixels * random.uniform(0.9, 1.1)  # ±10% size noise\n",
    "        size_pixels = max(0, int(size_pixels))\n",
    "\n",
    "        # Rainfall calculation with multiplicative noise (±10%)\n",
    "        base_rainfall = 0.08 * (intensity_dbz ** 1.5)\n",
    "        rainfall_factor = 1.0 + random.uniform(-0.1, 0.1)  # 10% up or down\n",
    "        rainfall_mmhr = base_rainfall * rainfall_factor\n",
    "        rainfall_mmhr = max(0.0, rainfall_mmhr)\n",
    "\n",
    "        if intensity_dbz == 0.0:\n",
    "            rainfall_mmhr = 0.0\n",
    "\n",
    "        # Movement (unchanged)\n",
    "        vx = base_vx + np.random.normal(0, movement_randomness_scale)\n",
    "        vy = base_vy + np.random.normal(0, movement_randomness_scale)\n",
    "        x_position += vx * (time_step_minutes / 60)\n",
    "        y_position += vy * (time_step_minutes / 60)\n",
    "\n",
    "        records.append({\n",
    "            'cell_id': cell_id,\n",
    "            'timestamp_utc': current_time,\n",
    "            'formation_time_utc': formation_time,\n",
    "            'dissipation_time_utc': dissipation_time,\n",
    "            'lifetime_hours': lifetime_hours,\n",
    "            'time_since_formation_hours': time_elapsed_seconds / 3600,\n",
    "            'x_position': x_position,\n",
    "            'y_position': y_position,\n",
    "            'size_pixels': size_pixels,\n",
    "            'intensity_dbz': intensity_dbz,\n",
    "            'rainfall_mm_per_hr': rainfall_mmhr,\n",
    "            'intensity_change_rate': intensity_change_rate\n",
    "        })\n",
    "\n",
    "        previous_intensity = intensity_dbz\n",
    "        current_time += datetime.timedelta(minutes=time_step_minutes)\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "# ------------------ RUN SIMULATION ------------------\n",
    "print(\"--- Generating storms with all specified changes ---\")\n",
    "\n",
    "all_storm_data = []\n",
    "num_simulated_cells = 50000\n",
    "overall_start_date = datetime.datetime(2024, 8, 1, 0, 0, 0)\n",
    "overall_end_date = datetime.datetime(2024, 8, 5, 23, 59, 59)\n",
    "\n",
    "master_intensity_profile = generate_master_intensity_profile()\n",
    "\n",
    "for i in range(num_simulated_cells):\n",
    "    cell_records = generate_storm_cell_lifecycle(\n",
    "        cell_id=f'StormCell_{i+1:05d}',\n",
    "        start_date=overall_start_date,\n",
    "        end_date=overall_end_date,\n",
    "        target_peak_intensity_dbz=75,\n",
    "        base_vx=0.0,\n",
    "        base_vy=2.0,\n",
    "        movement_randomness_scale=0.2\n",
    "    )\n",
    "    all_storm_data.extend(cell_records)\n",
    "\n",
    "# Create DataFrame\n",
    "storm_df = pd.DataFrame(all_storm_data)\n",
    "storm_df = storm_df.sort_values(by=['cell_id', 'timestamp_utc']).reset_index(drop=True)\n",
    "\n",
    "# Save CSV\n",
    "output_file = \"scenario6_fixed_peak_50000.csv\"\n",
    "storm_df.to_csv(output_file, index=False, date_format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "print(f\"Generated {len(storm_df)} rows for {num_simulated_cells} storms → saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5ba677-3ef0-458b-9e44-ad66fa0d61c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 435202 entries, 0 to 435201\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   cell_id                     435202 non-null  object        \n",
      " 1   timestamp_utc               435202 non-null  datetime64[ns]\n",
      " 2   formation_time_utc          435202 non-null  datetime64[ns]\n",
      " 3   dissipation_time_utc        435202 non-null  datetime64[ns]\n",
      " 4   lifetime_hours              435202 non-null  float64       \n",
      " 5   time_since_formation_hours  435202 non-null  float64       \n",
      " 6   x_position                  435202 non-null  float64       \n",
      " 7   y_position                  435202 non-null  float64       \n",
      " 8   size_pixels                 435202 non-null  int64         \n",
      " 9   intensity_dbz               435202 non-null  float64       \n",
      " 10  rainfall_mm_per_hr          435202 non-null  float64       \n",
      " 11  intensity_change_rate       435202 non-null  float64       \n",
      "dtypes: datetime64[ns](3), float64(7), int64(1), object(1)\n",
      "memory usage: 39.8+ MB\n",
      "None\n",
      "\n",
      "First 5 rows of the DataFrame:\n",
      "           cell_id              timestamp_utc         formation_time_utc  \\\n",
      "0  StormCell_00001 2024-08-04 10:32:40.510416 2024-08-04 10:32:40.510416   \n",
      "1  StormCell_00001 2024-08-04 10:37:40.510416 2024-08-04 10:32:40.510416   \n",
      "2  StormCell_00001 2024-08-04 10:42:40.510416 2024-08-04 10:32:40.510416   \n",
      "3  StormCell_00001 2024-08-04 10:47:40.510416 2024-08-04 10:32:40.510416   \n",
      "4  StormCell_00001 2024-08-04 10:52:40.510416 2024-08-04 10:32:40.510416   \n",
      "\n",
      "        dissipation_time_utc  lifetime_hours  time_since_formation_hours  \\\n",
      "0 2024-08-04 10:55:53.108995        0.386833                    0.000000   \n",
      "1 2024-08-04 10:55:53.108995        0.386833                    0.083333   \n",
      "2 2024-08-04 10:55:53.108995        0.386833                    0.166667   \n",
      "3 2024-08-04 10:55:53.108995        0.386833                    0.250000   \n",
      "4 2024-08-04 10:55:53.108995        0.386833                    0.333333   \n",
      "\n",
      "   x_position  y_position  size_pixels  intensity_dbz  rainfall_mm_per_hr  \\\n",
      "0    0.016058    0.166096           21       0.501964            0.030995   \n",
      "1    0.040530    0.345195           28       4.117591            0.734398   \n",
      "2    0.010878    0.526325          152      75.000000           51.729297   \n",
      "3    0.007309    0.699978           28       4.022935            0.659549   \n",
      "4    0.016142    0.904895           19       0.054124            0.001040   \n",
      "\n",
      "   intensity_change_rate  \n",
      "0               6.023566  \n",
      "1              43.387529  \n",
      "2             850.588905  \n",
      "3            -851.724779  \n",
      "4             -47.625735  \n",
      "\n",
      "--- Verifying Peak Intensity ---\n",
      "Minimum peak intensity found: 75.00 dBZ\n",
      "Maximum peak intensity found: 75.00 dBZ\n",
      "Are all peak intensities approximately the same (within a tolerance of 0.1)? Yes\n",
      "Are all peak intensities approximately equal to the target of 75.0 dBZ? True\n",
      "\n",
      "--- Visualizing Two Unique Storm Lifecycles ---\n",
      "Plots saved to 'storm_lifecycles.png'.\n",
      "\n",
      "--- Calculating Statistics for All Storms ---\n",
      "\n",
      "Descriptive Statistics for all 50,000 Storms:\n",
      "       lifetime_hours  peak_intensity_dbz  peak_rainfall_mmhr  \\\n",
      "count    50000.000000             50000.0        50000.000000   \n",
      "mean         0.680008                75.0           51.960264   \n",
      "std          0.277517                 0.0            2.997737   \n",
      "min          0.250000                75.0           46.765922   \n",
      "25%          0.467221                75.0           49.369732   \n",
      "50%          0.672061                75.0           51.937300   \n",
      "75%          0.871342                75.0           54.555257   \n",
      "max          1.500000                75.0           57.157119   \n",
      "\n",
      "       average_intensity_dbz  total_rainfall_mm  \n",
      "count           50000.000000       50000.000000  \n",
      "mean               14.045813           5.241834  \n",
      "std                 3.387418           0.690265  \n",
      "min                 9.832663           3.976650  \n",
      "25%                11.610876           4.723186  \n",
      "50%                13.238547           5.136322  \n",
      "75%                15.653769           5.675960  \n",
      "max                21.855138           8.300737  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------- Load and Inspect Data --------------------\n",
    "# This script assumes the CSV file is in the same directory.\n",
    "# If you get a FileNotFoundError, please check the file path.\n",
    "file_path = \"scenario6_fixed_peak_50000.csv\"\n",
    "try:\n",
    "    storm_df = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please ensure the file is in the same directory as this script.\")\n",
    "    # Exit the script gracefully if the file is not found\n",
    "    exit()\n",
    "\n",
    "# Convert relevant columns to appropriate data types\n",
    "storm_df['timestamp_utc'] = pd.to_datetime(storm_df['timestamp_utc'])\n",
    "storm_df['formation_time_utc'] = pd.to_datetime(storm_df['formation_time_utc'])\n",
    "storm_df['dissipation_time_utc'] = pd.to_datetime(storm_df['dissipation_time_utc'])\n",
    "\n",
    "# Display initial information about the DataFrame\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(storm_df.info())\n",
    "\n",
    "print(\"\\nFirst 5 rows of the DataFrame:\")\n",
    "print(storm_df.head())\n",
    "\n",
    "# -------------------- 1. Verify Peak Intensity --------------------\n",
    "print(\"\\n--- Verifying Peak Intensity ---\")\n",
    "# Group by storm cell and find the maximum intensity for each\n",
    "peak_intensities = storm_df.groupby('cell_id')['intensity_dbz'].max()\n",
    "\n",
    "# Check if all peak intensities are approximately the same\n",
    "min_peak = peak_intensities.min()\n",
    "max_peak = peak_intensities.max()\n",
    "expected_peak = 75.0\n",
    "\n",
    "is_same_peak_intensity = np.isclose(min_peak, max_peak, atol=0.1)\n",
    "print(f\"Minimum peak intensity found: {min_peak:.2f} dBZ\")\n",
    "print(f\"Maximum peak intensity found: {max_peak:.2f} dBZ\")\n",
    "print(f\"Are all peak intensities approximately the same (within a tolerance of 0.1)? {'Yes' if is_same_peak_intensity else 'No'}\")\n",
    "print(f\"Are all peak intensities approximately equal to the target of {expected_peak} dBZ? {np.all(np.isclose(peak_intensities, expected_peak, atol=0.5))}\")\n",
    "\n",
    "\n",
    "# -------------------- 2. & 3. Visualize Two Unique Storm Lifecycles --------------------\n",
    "print(\"\\n--- Visualizing Two Unique Storm Lifecycles ---\")\n",
    "\n",
    "# Get two unique storm IDs with different lifetimes\n",
    "all_lifetimes = storm_df.groupby('cell_id')['lifetime_hours'].first()\n",
    "short_storm_id = all_lifetimes.idxmin()\n",
    "long_storm_id = all_lifetimes.idxmax()\n",
    "\n",
    "# Filter the data for these two storms\n",
    "storm1_df = storm_df[storm_df['cell_id'] == short_storm_id]\n",
    "storm2_df = storm_df[storm_df['cell_id'] == long_storm_id]\n",
    "\n",
    "# Create a figure with a 2x1 grid of subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=False)\n",
    "fig.suptitle('Comparison of Two Storm Cell Lifecycles', fontsize=16)\n",
    "\n",
    "# Plot Intensity vs. Lifetime\n",
    "axes[0].plot(storm1_df['time_since_formation_hours'], storm1_df['intensity_dbz'], label=f'Storm ID: {short_storm_id} (Lifetime: {storm1_df[\"lifetime_hours\"].iloc[0]:.2f} hrs)')\n",
    "axes[0].plot(storm2_df['time_since_formation_hours'], storm2_df['intensity_dbz'], label=f'Storm ID: {long_storm_id} (Lifetime: {storm2_df[\"lifetime_hours\"].iloc[0]:.2f} hrs)')\n",
    "axes[0].set_title('Intensity vs. Time Since Formation')\n",
    "axes[0].set_xlabel('Time Since Formation (hours)')\n",
    "axes[0].set_ylabel('Intensity (dBZ)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot Rainfall vs. Lifetime\n",
    "axes[1].plot(storm1_df['time_since_formation_hours'], storm1_df['rainfall_mm_per_hr'], label=f'Storm ID: {short_storm_id}')\n",
    "axes[1].plot(storm2_df['time_since_formation_hours'], storm2_df['rainfall_mm_per_hr'], label=f'Storm ID: {long_storm_id}')\n",
    "axes[1].set_title('Rainfall vs. Time Since Formation')\n",
    "axes[1].set_xlabel('Time Since Formation (hours)')\n",
    "axes[1].set_ylabel('Rainfall (mm/hr)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig('storm_lifecycles.png')\n",
    "plt.close()\n",
    "print(\"Plots saved to 'storm_lifecycles.png'.\")\n",
    "\n",
    "# -------------------- 4. Calculate Statistics for All Storms --------------------\n",
    "print(\"\\n--- Calculating Statistics for All Storms ---\")\n",
    "\n",
    "# Group by storm cell ID to calculate per-storm statistics\n",
    "grouped_storms = storm_df.groupby('cell_id')\n",
    "\n",
    "# Calculate key metrics for each storm\n",
    "storm_stats_df = pd.DataFrame({\n",
    "    'lifetime_hours': grouped_storms['lifetime_hours'].first(),\n",
    "    'peak_intensity_dbz': grouped_storms['intensity_dbz'].max(),\n",
    "    'peak_rainfall_mmhr': grouped_storms['rainfall_mm_per_hr'].max(),\n",
    "    'average_intensity_dbz': grouped_storms['intensity_dbz'].mean(),\n",
    "    'total_rainfall_mm': grouped_storms['rainfall_mm_per_hr'].sum() * (5/60) # Sum of rate * time_step_in_hours\n",
    "})\n",
    "\n",
    "# Calculate descriptive statistics for the entire simulation\n",
    "overall_stats_description = storm_stats_df.describe()\n",
    "\n",
    "print(\"\\nDescriptive Statistics for all 50,000 Storms:\")\n",
    "print(overall_stats_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70bfd8f-8087-4ebf-ba44-73d1993714a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
