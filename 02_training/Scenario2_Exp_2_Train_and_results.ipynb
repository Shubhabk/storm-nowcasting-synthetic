{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0083d64d-1d10-491c-b00f-25374bd986bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Analysis for Scenario 2: Fixed Lifetime, Variable Intensity ---\n",
      "Successfully loaded 950000 records from 'scenario7_fixed_lifetime_unique_intensity_50000.csv'.\n",
      "Nowcasting dataset has 150000 records (first 10 minutes of each storm).\n",
      "Performing feature engineering on initial 10-minute data...\n",
      "Feature engineering complete.\n",
      "Final dataset for training/testing has 50000 unique storms.\n",
      "Features have been scaled using StandardScaler.\n",
      "\n",
      "--- Model Training & Evaluation for Scenario 2 ---\n",
      "  Training Gradient Boosting for Lifetime Hours...\n",
      "  Training Random Forest for Lifetime Hours...\n",
      "  Training XGBoost for Lifetime Hours...\n",
      "  Training Ridge for Lifetime Hours...\n",
      "  Training Gradient Boosting for Peak Rainfall...\n",
      "  Training Random Forest for Peak Rainfall...\n",
      "  Training XGBoost for Peak Rainfall...\n",
      "  Training Ridge for Peak Rainfall...\n",
      "  Training Gradient Boosting for Total Rainfall...\n",
      "  Training Random Forest for Total Rainfall...\n",
      "  Training XGBoost for Total Rainfall...\n",
      "  Training Ridge for Total Rainfall...\n",
      "\n",
      "================================================================================\n",
      "Performance Metrics for Scenario 2 (Nowcasting from 10 min data)\n",
      "================================================================================\n",
      "\n",
      "Target: Lifetime Hours\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| Model             |   R-squared |   RMSE |    MSE |    MAE |\n",
      "+===================+=============+========+========+========+\n",
      "| Gradient Boosting |      1.0000 | 0.0000 | 0.0000 | 0.0000 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| Random Forest     |      1.0000 | 0.0000 | 0.0000 | 0.0000 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| XGBoost           |      1.0000 | 0.0000 | 0.0000 | 0.0000 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| Ridge             |      1.0000 | 0.0000 | 0.0000 | 0.0000 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "\n",
      "Target: Peak Rainfall\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| Model             |   R-squared |   RMSE |    MSE |    MAE |\n",
      "+===================+=============+========+========+========+\n",
      "| Gradient Boosting |      0.9709 | 1.2929 | 1.6716 | 1.0506 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| Random Forest     |      0.9706 | 1.3013 | 1.6933 | 1.0639 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| XGBoost           |      0.9708 | 1.2957 | 1.6789 | 1.0529 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| Ridge             |      0.9674 | 1.3699 | 1.8766 | 1.1090 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "\n",
      "Target: Total Rainfall\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| Model             |   R-squared |   RMSE |    MSE |    MAE |\n",
      "+===================+=============+========+========+========+\n",
      "| Gradient Boosting |      0.9886 | 0.1134 | 0.0129 | 0.0909 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| Random Forest     |      0.9880 | 0.1165 | 0.0136 | 0.0942 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| XGBoost           |      0.9884 | 0.1143 | 0.0131 | 0.0914 |\n",
      "+-------------------+-------------+--------+--------+--------+\n",
      "| Ridge             |      0.9847 | 0.1314 | 0.0173 | 0.1034 |\n",
      "+-------------------+-------------+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ------------------ HELPER FUNCTIONS ------------------\n",
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test, target_name):\n",
    "    \"\"\"Trains and evaluates four regression models.\"\"\"\n",
    "    models = {\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "        'XGBoost': XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42),\n",
    "        'Ridge': Ridge(alpha=1.0)\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        print(f\"  Training {name} for {target_name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        results.append([name, r2, rmse, mse, mae])\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ------------------ MAIN SCRIPT FOR SCENARIO 2 ------------------\n",
    "print(\"--- Starting Analysis for Scenario 2: Fixed Lifetime, Variable Intensity ---\")\n",
    "\n",
    "# Step 1: Load the data\n",
    "try:\n",
    "    storm_df = pd.read_csv(\"scenario7_fixed_lifetime_unique_intensity_50000.csv\")\n",
    "    storm_df['timestamp_utc'] = pd.to_datetime(storm_df['timestamp_utc'])\n",
    "    print(f\"Successfully loaded {len(storm_df)} records from 'scenario7_fixed_lifetime_unique_intensity_50000.csv'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'scenario7_fixed_lifetime_unique_intensity_50000.csv' not found. Please ensure the file is in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Nowcasting-style Data Preparation (First 10 minutes)\n",
    "initial_data_df = storm_df[storm_df['time_since_formation_hours'] <= 10/60]\n",
    "print(f\"Nowcasting dataset has {len(initial_data_df)} records (first 10 minutes of each storm).\")\n",
    "\n",
    "# Step 3: Corrected Feature Engineering\n",
    "print(\"Performing feature engineering on initial 10-minute data...\")\n",
    "\n",
    "# Calculate the slopes for each storm's initial phase\n",
    "initial_data_df = initial_data_df.sort_values(by=['cell_id', 'time_since_formation_hours'])\n",
    "slopes_df = initial_data_df.groupby('cell_id').apply(\n",
    "    lambda group: pd.Series({\n",
    "        'intensity_slope': (group['intensity_dbz'].iloc[-1] - group['intensity_dbz'].iloc[0]) / (group['time_since_formation_hours'].iloc[-1] - group['time_since_formation_hours'].iloc[0]) if len(group) > 1 and group['time_since_formation_hours'].iloc[-1] != group['time_since_formation_hours'].iloc[0] else 0,\n",
    "        'size_slope': (group['size_pixels'].iloc[-1] - group['size_pixels'].iloc[0]) / (group['time_since_formation_hours'].iloc[-1] - group['time_since_formation_hours'].iloc[0]) if len(group) > 1 and group['time_since_formation_hours'].iloc[-1] != group['time_since_formation_hours'].iloc[0] else 0,\n",
    "        'rainfall_slope': (group['rainfall_mm_per_hr'].iloc[-1] - group['rainfall_mm_per_hr'].iloc[0]) / (group['time_since_formation_hours'].iloc[-1] - group['time_since_formation_hours'].iloc[0]) if len(group) > 1 and group['time_since_formation_hours'].iloc[-1] != group['time_since_formation_hours'].iloc[0] else 0\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Now, perform the rest of the feature engineering using simple aggregations\n",
    "engineered_features_stats = initial_data_df.groupby('cell_id').agg(\n",
    "    initial_intensity_dbz=('intensity_dbz', 'first'),\n",
    "    initial_size_pixels=('size_pixels', 'first'),\n",
    "    initial_rainfall_mm_per_hr=('rainfall_mm_per_hr', 'first'),\n",
    "    max_intensity_10min=('intensity_dbz', 'max'),\n",
    "    max_size_10min=('size_pixels', 'max'),\n",
    "    max_rainfall_10min=('rainfall_mm_per_hr', 'max'),\n",
    "    mean_intensity_10min=('intensity_dbz', 'mean'),\n",
    "    mean_size_10min=('size_pixels', 'mean'),\n",
    "    mean_rainfall_10min=('rainfall_mm_per_hr', 'mean'),\n",
    ").reset_index()\n",
    "\n",
    "# Merge the stats and slopes\n",
    "engineered_features = pd.merge(engineered_features_stats, slopes_df, on='cell_id', how='left')\n",
    "print(\"Feature engineering complete.\")\n",
    "\n",
    "# Step 4: Aggregate targets from the full dataset\n",
    "targets_df = storm_df.groupby('cell_id').agg(\n",
    "    lifetime_hours=('lifetime_hours', 'first'),\n",
    "    peak_rainfall_mmhr=('rainfall_mm_per_hr', 'max'),\n",
    "    total_rainfall_mm=('rainfall_mm_per_hr', lambda x: (x * (5/60)).sum())\n",
    ").reset_index()\n",
    "\n",
    "# Step 5: Merge features with targets\n",
    "dataset = pd.merge(engineered_features, targets_df, on='cell_id', how='inner')\n",
    "dataset.dropna(inplace=True)\n",
    "print(f\"Final dataset for training/testing has {len(dataset)} unique storms.\")\n",
    "\n",
    "# Step 6: Split the data\n",
    "cell_ids = dataset['cell_id'].unique()\n",
    "train_ids, test_ids = train_test_split(cell_ids, test_size=20000, train_size=30000, random_state=42, shuffle=True)\n",
    "\n",
    "train_df = dataset[dataset['cell_id'].isin(train_ids)]\n",
    "test_df = dataset[dataset['cell_id'].isin(test_ids)]\n",
    "\n",
    "X_train = train_df.drop(['cell_id', 'lifetime_hours', 'peak_rainfall_mmhr', 'total_rainfall_mm'], axis=1)\n",
    "y_train_lifetime = train_df['lifetime_hours']\n",
    "y_train_peak_rainfall = train_df['peak_rainfall_mmhr']\n",
    "y_train_total_rainfall = train_df['total_rainfall_mm']\n",
    "\n",
    "X_test = test_df.drop(['cell_id', 'lifetime_hours', 'peak_rainfall_mmhr', 'total_rainfall_mm'], axis=1)\n",
    "y_test_lifetime = test_df['lifetime_hours']\n",
    "y_test_peak_rainfall = test_df['peak_rainfall_mmhr']\n",
    "y_test_total_rainfall = test_df['total_rainfall_mm']\n",
    "\n",
    "# Step 7: Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Features have been scaled using StandardScaler.\")\n",
    "\n",
    "# Step 8: Train and Evaluate models for each target\n",
    "print(\"\\n--- Model Training & Evaluation for Scenario 2 ---\")\n",
    "all_results = {}\n",
    "all_results['Lifetime Hours'] = train_and_evaluate_models(X_train_scaled, y_train_lifetime, X_test_scaled, y_test_lifetime, 'Lifetime Hours')\n",
    "all_results['Peak Rainfall'] = train_and_evaluate_models(X_train_scaled, y_train_peak_rainfall, X_test_scaled, y_test_peak_rainfall, 'Peak Rainfall')\n",
    "all_results['Total Rainfall'] = train_and_evaluate_models(X_train_scaled, y_train_total_rainfall, X_test_scaled, y_test_total_rainfall, 'Total Rainfall')\n",
    "\n",
    "# Step 9: Print results in a single table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Performance Metrics for Scenario 2 (Nowcasting from 10 min data)\")\n",
    "print(\"=\"*80)\n",
    "for target, results in all_results.items():\n",
    "    print(f\"\\nTarget: {target}\")\n",
    "    headers = [\"Model\", \"R-squared\", \"RMSE\", \"MSE\", \"MAE\"]\n",
    "    print(tabulate(results, headers=headers, tablefmt=\"grid\", floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799ad03-ce78-406c-bcee-1555957d39d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
